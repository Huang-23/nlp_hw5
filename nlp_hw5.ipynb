{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "num = 0\n",
    "train_data = []\n",
    "test_data = []\n",
    "train_size = 5000\n",
    "test_size = 100\n",
    "\n",
    "input_file = open('translation2019zh_train.json', encoding = 'utf8')\n",
    "for line in input_file.readlines():\n",
    "    num = num + 1\n",
    "    if num > train_size + test_size:\n",
    "        break\n",
    "    elif num > train_size:\n",
    "        test_data.append(json.loads(line))\n",
    "    else:\n",
    "        train_data.append(json.loads(line))\n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 簡繁體轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opencc import OpenCC\n",
    "\n",
    "cc = OpenCC('s2t')\n",
    "\n",
    "for data in train_data:\n",
    "    data['chinese'] = cc.convert(data['chinese'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整理為中文及英文字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t爲了更好的銳度，但是附帶的會多一些顆粒度，可以使用這個顯影劑的1：1稀釋液。\\n', '\\t他還把宣揚自己思想的所謂《綠皮書》稱作“新福音書”。\\n', '\\t微風推着我去愛撫它的長耳朵\\n', '\\t它們的先烈們的鮮血是白流了…\\n', '\\t最後，在1月31日，湖人將前往汽車城底特律挑戰活塞隊，活塞近來在東部排名第二。\\n', '\\t“真是天造地設的一對——我父親喜歡結交名人，傑姬酷愛金錢，”亞歷山大在婚禮上譏諷道。他和克里斯蒂娜從未同他們的繼母和睦相處過。\\n', '\\t2006年，沃爾瑪的推薦引擎竟將《人猿星球》與馬丁·路德·金的記錄片配成了一對，爲此沃爾瑪遭到了種族歧視的指控。\\n', '\\t通過電子探針顯微分析確定貧化渣中主要銅相爲冰銅相。\\n', '\\t吉姆靠給人擦皮鞋爲生。\\n', '\\t用甘氨酸模擬膠原，研究間苯二酚-惡唑烷E鞣性基質的形成以及與膠原之間的反應特性。\\n']\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料檔，並將所有單字整理為字典，分別為英文及中文字典，注意，英文為字母的集合，非單字(Word)\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "\n",
    "for item in train_data:\n",
    "    input_text = item['english']\n",
    "    target_text = '\\t' + item['chinese'] + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "            \n",
    "print(target_texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
